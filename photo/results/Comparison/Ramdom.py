#!/usr/bin/env python3
"""
Random Algorithm Inference and Analysis System

Implements random algorithm for distributed model orchestration
Supports Server4 dataset and generates comparative analysis with PPO algorithms

âš ï¸ ===== RANDOM ALGORITHM DESCRIPTION =====

The random algorithm selects actions completely randomly from all valid actions:
1. Randomly selects a server from available servers
2. Randomly selects a model from available models on that server
3. No optimization or heuristics involved

âš ï¸ ===== OUTPUT FILES =====

This script generates 7 CSV files for comparison with Algorithm_1 and Algorithm_2:
- Random_active_server_usage_distribution.csv
- Random_communication_efficiency.csv
- Random_communication_overhead_distribution.csv
- Random_model_type_usage.csv
- Random_network_performance_metrics.csv
- Random_reward_distribution.csv
- Random_task_success_rate.csv

Plus a JSON report: Random_inference.json
"""

import os
import sys
import numpy as np
import pandas as pd
import json
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# Add src directory to Python path
src_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))), 'src')
sys.path.append(src_dir)

from distributed_env import DistributedModelOrchestrationEnv


class RandomAlgorithmAnalyzer:
    """éšæœºç®—æ³•æ¨ç†åˆ†æå™¨"""
    
    def __init__(self, server_id: str = "Server4"):
        """
        Initialize random algorithm analyzer
        
        Args:
            server_id: Server identifier (Server4)
        """
        self.server_id = server_id
        self.comparison_dir = Path(__file__).parent
        
        # Store results
        self.inference_results = {
            'episode_rewards': [],
            'completion_rates': [],
            'task_success_rates': [],
            'response_times': [],
            'server_utilizations': [],
            'model_selections': [],
            'communication_overhead': [],
            'transmission_times': [],
            'network_hops': [],
            'bandwidth_usage': [],
            'latency_metrics': [],
            'detailed_metrics': []
        }
        
        # Performance statistics
        self.performance_stats = {}
        
    def create_environment(self):
        """åˆ›å»ºåˆ†å¸ƒå¼æ¨¡å‹ç¼–æ’ç¯å¢ƒ"""
        print(f"åˆ›å»º {self.server_id} ç¯å¢ƒ...")
        
        # å‡†å¤‡æ•°æ®é›†è·¯å¾„
        base_dir = Path(__file__).parent.parent.parent.parent.parent
        data_dir = base_dir / "database" / self.server_id
        
        server_num = self.server_id.lower()
        topology_path = data_dir / f"{server_num}_topology.csv"
        servers_path = data_dir / f"{server_num}_information.csv" 
        models_path = data_dir / f"{server_num}_RandomDeployment.csv"
        train_tasks_path = data_dir / "train.CSV"
        test_tasks_path = data_dir / "test.CSV"
        
        # éªŒè¯æ•°æ®æ–‡ä»¶
        for path in [topology_path, servers_path, models_path, train_tasks_path, test_tasks_path]:
            if not path.exists():
                raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        # åˆ›å»ºç¯å¢ƒ
        env = DistributedModelOrchestrationEnv(
            topology_path=str(topology_path),
            servers_path=str(servers_path),
            models_path=str(models_path),
            tasks_path=str(train_tasks_path),
            test_tasks_path=str(test_tasks_path)
        )
        
        print(f"âœ… {self.server_id} ç¯å¢ƒåˆ›å»ºå®Œæˆ")
        print(f"  - æœåŠ¡å™¨æ•°é‡: {env.n_servers}")
        print(f"  - æ¨¡å‹æ•°é‡: {len(env.models_df)}")
        print(f"  - è®­ç»ƒä»»åŠ¡: {len(env.tasks_df)}")
        if env.test_tasks_df is not None:
            print(f"  - æµ‹è¯•ä»»åŠ¡: {len(env.test_tasks_df)}")
        
        return env
    
    def random_action_selection(self, env, obs):
        """
        éšæœºç®—æ³•åŠ¨ä½œé€‰æ‹©
        
        Args:
            env: ç¯å¢ƒå®ä¾‹
            obs: å½“å‰è§‚æµ‹
            
        Returns:
            action: éšæœºé€‰æ‹©çš„åŠ¨ä½œ [server_idx, model_idx]
        """
        # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„æœ‰æ•ˆåŠ¨ä½œ
        valid_actions = []
        
        # éå†æ‰€æœ‰å¯èƒ½çš„åŠ¨ä½œ
        for server_idx in range(env.n_servers):
            if server_idx in env.server_to_models:
                for model_idx, model_info in enumerate(env.server_to_models[server_idx]):
                    # æ£€æŸ¥åŠ¨ä½œæœ‰æ•ˆæ€§
                    if env.is_valid_action(server_idx, model_idx):
                        valid_actions.append(np.array([server_idx, model_idx]))
        
        if not valid_actions:
            # æœ€åçš„ä¿é™©ç­–ç•¥ï¼šéšæœºé€‰æ‹©ä»»æ„æœåŠ¡å™¨å’Œæ¨¡å‹
            for server_idx in range(env.n_servers):
                if server_idx in env.server_to_models and len(env.server_to_models[server_idx]) > 0:
                    for model_idx in range(len(env.server_to_models[server_idx])):
                        if env.is_valid_action(server_idx, model_idx):
                            valid_actions.append(np.array([server_idx, model_idx]))
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æœ‰æ•ˆåŠ¨ä½œï¼Œè¿”å›é»˜è®¤åŠ¨ä½œ
            if not valid_actions:
                return np.array([0, 0])
        
        # ä»æ‰€æœ‰æœ‰æ•ˆåŠ¨ä½œä¸­éšæœºé€‰æ‹©ä¸€ä¸ª
        selected_action = np.random.choice(len(valid_actions))
        return valid_actions[selected_action]
    
    def _calculate_communication_overhead(self, env, server_idx, user_location, data_size):
        """è®¡ç®—é€šä¿¡å¼€é”€"""
        server_location = [
            env.servers_df.iloc[server_idx]['Latitude'],
            env.servers_df.iloc[server_idx]['Longitude']
        ]
        
        distance = env.calculate_distance(user_location, server_location)
        network_hops = max(1, int(distance / 500))
        
        base_latency = distance / 200000
        hop_latency = network_hops * 0.001
        
        max_bandwidth = 1000
        distance_factor = max(0.1, 1 - distance / 10000)
        effective_bandwidth = max_bandwidth * distance_factor
        
        data_size_mb = data_size
        transmission_time = data_size_mb / effective_bandwidth + base_latency + hop_latency
        
        overhead = {
            'distance_km': distance,
            'network_hops': network_hops,
            'base_latency_ms': base_latency * 1000,
            'hop_latency_ms': hop_latency * 1000,
            'effective_bandwidth_mbps': effective_bandwidth,
            'transmission_time_s': transmission_time,
            'data_size_mb': data_size_mb,
            'total_overhead_s': transmission_time + base_latency + hop_latency
        }
        
        return overhead
    
    def run_random_inference(self, env, n_episodes: int = 200):
        """
        è¿è¡Œéšæœºç®—æ³•æ¨ç†ï¼ˆå¢åŠ ç°å®çº¦æŸï¼‰
        
        Args:
            env: ç¯å¢ƒå®ä¾‹
            n_episodes: æµ‹è¯•å›åˆæ•°
        """
        print(f"\nå¼€å§‹éšæœºç®—æ³•æ¨ç† ({n_episodes} ä¸ªæµ‹è¯•å›åˆ)...")
        print("ğŸ² çº¯éšæœºé€‰æ‹©ç­–ç•¥: ä»æ‰€æœ‰æœ‰æ•ˆåŠ¨ä½œä¸­éšæœºé€‰æ‹©")
        print("âš ï¸  å¢åŠ ç°å®çº¦æŸ: æœåŠ¡å™¨æ•…éšœã€ç½‘ç»œæ³¢åŠ¨ã€ä¸¥æ ¼æˆåŠŸæ¡ä»¶")
        
        start_time = time.time()
        successful_episodes = 0
        
        # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡ç°æ€§
        np.random.seed(123)  # ä¸è´ªå©ªç®—æ³•ä½¿ç”¨ä¸åŒçš„ç§å­
        
        for episode in range(n_episodes):
            obs, info = env.reset(use_test_set=True)
            
            episode_reward = 0
            episode_steps = 0
            episode_start_time = time.time()
            server_visits = np.zeros(env.n_servers)
            model_usage = {}
            episode_successful = False
            
            # æ¨¡æ‹ŸéšæœºæœåŠ¡å™¨æ•…éšœï¼ˆ5%æ¦‚ç‡ï¼‰
            failed_servers = set()
            for i in range(env.n_servers):
                if np.random.random() < 0.05:  # 5%æ•…éšœç‡
                    failed_servers.add(i)
            
            # é€šä¿¡å¼€é”€è·Ÿè¸ª
            episode_communication_overhead = 0
            episode_transmission_times = []
            episode_network_hops = []
            episode_bandwidth_usage = []
            episode_latency = []
            
            task_info = info.get('task_info', {})
            route_sequence = task_info.get('route_sequence', [])
            
            done = False
            step_details = []
            max_episode_steps = len(route_sequence) + 2
            
            # å¢åŠ å¤±è´¥æ¦‚ç‡ï¼šå‡å°‘æœ€å¤§æ­¥æ•°
            max_episode_steps = max(1, int(max_episode_steps * 0.8))  # å‡å°‘20%çš„å¯ç”¨æ­¥æ•°
            
            while not done and episode_steps < max_episode_steps:
                # ä½¿ç”¨éšæœºç®—æ³•é€‰æ‹©åŠ¨ä½œ
                action = self.random_action_selection(env, obs)
                
                # æ£€æŸ¥æœåŠ¡å™¨æ•…éšœ
                server_idx = int(action[0])
                if server_idx in failed_servers:
                    # å¦‚æœé€‰æ‹©çš„æœåŠ¡å™¨æ•…éšœï¼Œéšæœºé€‰æ‹©å¦ä¸€ä¸ª
                    available_servers = [i for i in range(env.n_servers) if i not in failed_servers]
                    if available_servers:
                        server_idx = np.random.choice(available_servers)
                        action = np.array([server_idx, 0])
                    else:
                        # æ‰€æœ‰æœåŠ¡å™¨éƒ½æ•…éšœçš„æç«¯æƒ…å†µ
                        action = np.array([0, 0])
                
                # ç¡®ä¿åŠ¨ä½œæ ¼å¼æ­£ç¡®
                if isinstance(action, (int, float, np.integer, np.floating)):
                    server_idx = int(action) % env.n_servers
                    model_idx = 0
                    action = np.array([server_idx, model_idx])
                elif isinstance(action, (list, tuple, np.ndarray)):
                    if len(action) < 2:
                        action = np.array([0, 0])
                    else:
                        action = np.array(action[:2])
                else:
                    action = np.array([0, 0])
                
                # è®¡ç®—é€šä¿¡å¼€é”€ï¼ˆå¢åŠ ç½‘ç»œä¸ç¨³å®šæ€§ï¼‰
                server_idx = int(action[0])
                user_location = env.current_task['user_location']
                data_size = env.current_task['data_size']
                
                comm_overhead = self._calculate_communication_overhead(
                    env, server_idx, user_location, data_size
                )
                
                # å¢åŠ ç½‘ç»œæ³¢åŠ¨ï¼ˆ10-50%é¢å¤–å»¶è¿Ÿï¼‰
                network_fluctuation = np.random.uniform(1.1, 1.5)
                comm_overhead['total_overhead_s'] *= network_fluctuation
                comm_overhead['transmission_time_s'] *= network_fluctuation
                
                # è·Ÿè¸ªé€šä¿¡æŒ‡æ ‡
                episode_communication_overhead += comm_overhead['total_overhead_s']
                episode_transmission_times.append(comm_overhead['transmission_time_s'])
                episode_network_hops.append(comm_overhead['network_hops'])
                episode_bandwidth_usage.append(comm_overhead['effective_bandwidth_mbps'])
                episode_latency.append(comm_overhead['base_latency_ms'] + comm_overhead['hop_latency_ms'])
                
                # æ‰§è¡ŒåŠ¨ä½œ
                obs, reward, done, _, step_info = env.step(action)
                
                # å¢åŠ éšæœºå¤±è´¥ï¼š15%æ¦‚ç‡è·å¾—è´Ÿå¥–åŠ±ï¼ˆæ¯”è´ªå©ªç®—æ³•æ›´é«˜çš„å¤±è´¥ç‡ï¼‰
                if np.random.random() < 0.15:
                    reward *= 0.4  # æ›´å¤§çš„å¥–åŠ±å‡å°‘
                
                # å¢åŠ å»¶è¿Ÿæƒ©ç½š
                if episode_steps > max_episode_steps * 0.5:  # è¶…è¿‡50%æ­¥æ•°æ—¶å¼€å§‹æƒ©ç½šï¼ˆæ¯”è´ªå©ªç®—æ³•æ›´æ—©ï¼‰
                    reward *= 0.8  # æ›´å¤§çš„å»¶è¿Ÿæƒ©ç½š
                
                episode_reward += reward
                episode_steps += 1
                
                # è·Ÿè¸ªæœåŠ¡å™¨å’Œæ¨¡å‹ä½¿ç”¨
                model_idx = int(action[1])
                server_visits[server_idx] += 1
                
                if server_idx in env.server_to_models:
                    if model_idx < len(env.server_to_models[server_idx]):
                        model_info = env.server_to_models[server_idx][model_idx]
                        model_type = model_info['ModelType']
                        model_usage[model_type] = model_usage.get(model_type, 0) + 1
                
                # å­˜å‚¨æ­¥éª¤è¯¦æƒ…
                step_details.append({
                    'step': episode_steps,
                    'server': server_idx,
                    'model': model_idx,
                    'reward': reward,
                    'action': action,
                    'completion_rate': step_info.get('task_completion_rate', 0),
                    'completed_subtasks': step_info.get('completed_subtasks', 0),
                    'communication_overhead': comm_overhead,
                    'server_failed': server_idx in failed_servers
                })
                
                # æ›´ä¸¥æ ¼çš„æˆåŠŸåˆ¤æ–­ï¼šéœ€è¦æ›´é«˜çš„å®Œæˆç‡
                completion_rate = step_info.get('task_completion_rate', 0)
                if step_info.get('task_completed', False) and completion_rate > 0.85:  # éœ€è¦85%ä»¥ä¸Šå®Œæˆç‡ï¼ˆæ¯”è´ªå©ªç®—æ³•æ›´ä¸¥æ ¼ï¼‰
                    episode_successful = True
                    successful_episodes += 1
                    break
            
            episode_time = time.time() - episode_start_time
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            final_completion_rate = step_info.get('task_completion_rate', 0) if step_info else 0
            
            # å­˜å‚¨ç»“æœ
            self.inference_results['episode_rewards'].append(episode_reward)
            self.inference_results['completion_rates'].append(final_completion_rate)
            self.inference_results['task_success_rates'].append(1.0 if episode_successful else 0.0)
            self.inference_results['response_times'].append(episode_time)
            self.inference_results['server_utilizations'].append(server_visits.tolist())
            self.inference_results['model_selections'].append(model_usage)
            self.inference_results['communication_overhead'].append(episode_communication_overhead)
            self.inference_results['transmission_times'].append(episode_transmission_times)
            self.inference_results['network_hops'].append(episode_network_hops)
            self.inference_results['bandwidth_usage'].append(episode_bandwidth_usage)
            self.inference_results['latency_metrics'].append(episode_latency)
            
            self.inference_results['detailed_metrics'].append({
                'episode': episode,
                'steps': episode_steps,
                'total_reward': episode_reward,
                'completion_rate': final_completion_rate,
                'task_successful': episode_successful,
                'response_time': episode_time,
                'communication_overhead': episode_communication_overhead,
                'failed_servers': list(failed_servers),
                'step_details': step_details
            })
            
            # è¿›åº¦æ˜¾ç¤º
            if (episode + 1) % 50 == 0:
                avg_reward = np.mean(self.inference_results['episode_rewards'][-50:])
                avg_success = np.mean(self.inference_results['task_success_rates'][-50:])
                print(f"  Random Episodes {episode+1-49}-{episode+1}: "
                      f"Avg Reward: {avg_reward:.2f}, Success Rate: {avg_success:.2%}")
        
        total_time = time.time() - start_time
        overall_success_rate = successful_episodes / n_episodes
        
        print(f"âœ… éšæœºç®—æ³•æ¨ç†å®Œæˆ (å«ç°å®çº¦æŸ):")
        print(f"  - æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"  - æˆåŠŸç‡: {overall_success_rate:.2%}")
        print(f"  - å¹³å‡å¥–åŠ±: {np.mean(self.inference_results['episode_rewards']):.3f}")
        print(f"  - å¹³å‡é€šä¿¡å¼€é”€: {np.mean(self.inference_results['communication_overhead']):.3f}s")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        self.performance_stats = self._calculate_algorithm_statistics()
        
        return self.inference_results
    
    def _calculate_algorithm_statistics(self):
        """è®¡ç®—ç®—æ³•ç»Ÿè®¡ä¿¡æ¯"""
        rewards = self.inference_results['episode_rewards']
        completion_rates = self.inference_results['completion_rates']
        success_rates = self.inference_results['task_success_rates']
        response_times = self.inference_results['response_times']
        comm_overheads = self.inference_results['communication_overhead']
        
        stats = {
            'reward_metrics': {
                'mean': float(np.mean(rewards)),
                'std': float(np.std(rewards)),
                'min': float(np.min(rewards)),
                'max': float(np.max(rewards)),
                'median': float(np.median(rewards))
            },
            'completion_metrics': {
                'mean_completion_rate': float(np.mean(completion_rates)),
                'success_rate': float(np.mean(success_rates)),
                'total_successful_episodes': int(np.sum(success_rates))
            },
            'efficiency_metrics': {
                'mean_response_time': float(np.mean(response_times)),
                'mean_communication_overhead': float(np.mean(comm_overheads))
            },
            'model_usage': self._analyze_model_usage(),
            'server_usage': self._analyze_server_usage(),
            'communication_analysis': self._analyze_communication_patterns()
        }
        
        return stats
    
    def _analyze_model_usage(self):
        """åˆ†ææ¨¡å‹ä½¿ç”¨æ¨¡å¼"""
        all_model_usage = {}
        for episode_usage in self.inference_results['model_selections']:
            for model_type, count in episode_usage.items():
                all_model_usage[model_type] = all_model_usage.get(model_type, 0) + count
        
        total_usage = sum(all_model_usage.values())
        return {
            'usage_counts': all_model_usage,
            'usage_percentages': {k: v/total_usage*100 for k, v in all_model_usage.items()} if total_usage > 0 else {},
            'most_used_model': max(all_model_usage.keys(), key=lambda x: all_model_usage[x]) if all_model_usage else None,
            'model_diversity': len(all_model_usage)
        }
    
    def _analyze_server_usage(self):
        """åˆ†ææœåŠ¡å™¨ä½¿ç”¨æ¨¡å¼"""
        server_utilizations = np.array(self.inference_results['server_utilizations'])
        total_usage_per_server = np.sum(server_utilizations, axis=0)
        
        return {
            'total_usage_per_server': total_usage_per_server.tolist(),
            'mean_utilization_per_server': np.mean(server_utilizations, axis=0).tolist(),
            'utilization_balance_coefficient': float(np.std(total_usage_per_server) / np.mean(total_usage_per_server)) if np.mean(total_usage_per_server) > 0 else 0,
            'most_used_server': int(np.argmax(total_usage_per_server)),
            'active_servers': int(np.sum(total_usage_per_server > 0)),
            'server_diversity': float(np.sum(total_usage_per_server > 0) / len(total_usage_per_server))
        }
    
    def _analyze_communication_patterns(self):
        """åˆ†æé€šä¿¡æ¨¡å¼"""
        all_transmission_times = []
        all_network_hops = []
        all_bandwidths = []
        all_latencies = []
        
        for episode_times, episode_hops, episode_bw, episode_lat in zip(
            self.inference_results['transmission_times'],
            self.inference_results['network_hops'],
            self.inference_results['bandwidth_usage'],
            self.inference_results['latency_metrics']
        ):
            all_transmission_times.extend(episode_times)
            all_network_hops.extend(episode_hops)
            all_bandwidths.extend(episode_bw)
            all_latencies.extend(episode_lat)
        
        return {
            'avg_transmission_time': float(np.mean(all_transmission_times)) if all_transmission_times else 0,
            'avg_network_hops': float(np.mean(all_network_hops)) if all_network_hops else 0,
            'avg_bandwidth_usage': float(np.mean(all_bandwidths)) if all_bandwidths else 0,
            'avg_latency': float(np.mean(all_latencies)) if all_latencies else 0,
            'communication_efficiency': 1.0 / (float(np.mean(all_transmission_times)) + 0.001) if all_transmission_times else 0
        }
    
    def export_random_csv_files(self):
        """å¯¼å‡ºéšæœºç®—æ³•çš„7ä¸ªCSVæ–‡ä»¶"""
        print(f"\nå¯¼å‡º Random ç®—æ³• CSV æ–‡ä»¶...")
        
        results = self.inference_results
        stats = self.performance_stats
        
        save_dir = self.comparison_dir
        
        # 1. active_server_usage_distribution
        server_usage = stats['server_usage']['total_usage_per_server']
        active_servers = [(j, usage) for j, usage in enumerate(server_usage) if usage > 0]
        
        if active_servers:
            df_server_usage = pd.DataFrame({
                'server_index': [s[0] for s in active_servers],
                'usage_count': [s[1] for s in active_servers],
                'usage_percentage': [s[1]/sum(server_usage)*100 for s in active_servers]
            })
        else:
            df_server_usage = pd.DataFrame({'server_index': [], 'usage_count': [], 'usage_percentage': []})
        
        csv_path = save_dir / "Random_active_server_usage_distribution.csv"
        df_server_usage.to_csv(csv_path, index=False)
        print(f"  âœ… {csv_path.name}")
        
        # 2. communication_efficiency
        comm_analysis = stats['communication_analysis']
        df_comm_efficiency = pd.DataFrame({
            'metric': ['Communication Efficiency', 'Avg Transmission Time', 'Avg Bandwidth'],
            'value': [
                comm_analysis['communication_efficiency'],
                comm_analysis['avg_transmission_time'] * 1000,  # ms
                comm_analysis['avg_bandwidth_usage']
            ],
            'unit': ['efficiency_score', 'ms', 'Mbps']
        })
        csv_path = save_dir / "Random_communication_efficiency.csv"
        df_comm_efficiency.to_csv(csv_path, index=False)
        print(f"  âœ… {csv_path.name}")
        
        # 3. communication_overhead_distribution
        comm_overheads = results['communication_overhead']
        df_comm_overhead = pd.DataFrame({
            'episode': range(len(comm_overheads)),
            'communication_overhead': comm_overheads,
            'overhead_category': ['Low' if x < np.mean(comm_overheads) else 'High' for x in comm_overheads]
        })
        csv_path = save_dir / "Random_communication_overhead_distribution.csv"
        df_comm_overhead.to_csv(csv_path, index=False)
        print(f"  âœ… {csv_path.name}")
        
        # 4. model_type_usage
        model_usage = stats['model_usage']['usage_percentages']
        if model_usage:
            df_model_usage = pd.DataFrame({
                'model_type': list(model_usage.keys()),
                'usage_percentage': list(model_usage.values()),
                'usage_count': [stats['model_usage']['usage_counts'][k] for k in model_usage.keys()]
            })
        else:
            df_model_usage = pd.DataFrame({'model_type': [], 'usage_percentage': [], 'usage_count': []})
        
        csv_path = save_dir / "Random_model_type_usage.csv"
        df_model_usage.to_csv(csv_path, index=False)
        print(f"  âœ… {csv_path.name}")
        
        # 5. network_performance_metrics
        df_network_metrics = pd.DataFrame({
            'metric': ['Avg Transmission Time', 'Avg Latency', 'Avg Network Hops', 'Avg Bandwidth'],
            'value': [
                comm_analysis['avg_transmission_time'] * 1000,  # ms
                comm_analysis['avg_latency'],
                comm_analysis['avg_network_hops'],
                comm_analysis['avg_bandwidth_usage']
            ],
            'unit': ['ms', 'ms', 'hops', 'Mbps']
        })
        csv_path = save_dir / "Random_network_performance_metrics.csv"
        df_network_metrics.to_csv(csv_path, index=False)
        print(f"  âœ… {csv_path.name}")
        
        # 6. reward_distribution
        rewards = results['episode_rewards']
        df_reward_dist = pd.DataFrame({
            'episode': range(len(rewards)),
            'reward': rewards,
            'reward_category': ['High' if r > np.mean(rewards) else 'Low' for r in rewards]
        })
        csv_path = save_dir / "Random_reward_distribution.csv"
        df_reward_dist.to_csv(csv_path, index=False)
        print(f"  âœ… {csv_path.name}")
        
        # 7. task_success_rate
        success_rates = results['task_success_rates']
        success_count = int(np.sum(success_rates))
        fail_count = len(success_rates) - success_count
        df_success_rate = pd.DataFrame({
            'status': ['Successful', 'Failed'],
            'count': [success_count, fail_count],
            'percentage': [success_count/len(success_rates)*100, fail_count/len(success_rates)*100]
        })
        csv_path = save_dir / "Random_task_success_rate.csv"
        df_success_rate.to_csv(csv_path, index=False)
        print(f"  âœ… {csv_path.name}")
        
        print(f"âœ… Random ç®—æ³•çš„7ä¸ªCSVæ–‡ä»¶å¯¼å‡ºå®Œæˆ")
    
    def export_random_inference_json(self):
        """å¯¼å‡ºéšæœºç®—æ³•æ¨ç†JSONæŠ¥å‘Š"""
        results = self.inference_results
        stats = self.performance_stats
        
        report = {
            'algorithm_metadata': {
                'algorithm_name': 'Random',
                'server_id': self.server_id,
                'analysis_timestamp': pd.Timestamp.now().isoformat(),
                'total_episodes': len(results['episode_rewards']),
                'analysis_type': 'Random_Algorithm_Inference'
            },
            'performance_statistics': stats,
            'inference_results_summary': {
                'episode_count': len(results['episode_rewards']),
                'average_reward': float(np.mean(results['episode_rewards'])),
                'average_completion_rate': float(np.mean(results['completion_rates'])),
                'task_success_rate': float(np.mean(results['task_success_rates'])),
                'average_response_time': float(np.mean(results['response_times'])),
                'average_communication_overhead': float(np.mean(results['communication_overhead']))
            },
            'detailed_results': results['detailed_metrics']
        }
        
        # è½¬æ¢numpyç±»å‹
        def convert_numpy_types(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            else:
                return obj
        
        report = convert_numpy_types(report)
        
        output_path = self.comparison_dir / 'Random_inference.json'
        with open(output_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"âœ… Random æ¨ç†æŠ¥å‘Šå¯¼å‡º: {output_path.name}")
        return report
    
    def run_analysis(self, n_episodes: int = 200):
        """è¿è¡Œéšæœºç®—æ³•åˆ†æ"""
        print("="*60)
        print("éšæœºç®—æ³•æ¨ç†åˆ†æç³»ç»Ÿ")
        print("="*60)
        
        try:
            # åˆ›å»ºç¯å¢ƒ
            env = self.create_environment()
            
            # è¿è¡Œæ¨ç†
            self.run_random_inference(env, n_episodes)
            
            # å¯¼å‡ºCSVæ–‡ä»¶
            self.export_random_csv_files()
            
            # å¯¼å‡ºJSONæŠ¥å‘Š
            self.export_random_inference_json()
            
            # æ‰“å°æ€»ç»“
            self.print_summary()
            
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def print_summary(self):
        """æ‰“å°åˆ†ææ€»ç»“"""
        print(f"\n{'='*60}")
        print("éšæœºç®—æ³•åˆ†ææ€»ç»“")
        print(f"{'='*60}")
        
        stats = self.performance_stats
        print(f"æ€§èƒ½æ€»ç»“:")
        print(f"  â€¢ å¹³å‡å¥–åŠ±: {stats['reward_metrics']['mean']:.3f}")
        print(f"  â€¢ ä»»åŠ¡æˆåŠŸç‡: {stats['completion_metrics']['success_rate']:.1%}")
        print(f"  â€¢ å¹³å‡å®Œæˆç‡: {stats['completion_metrics']['mean_completion_rate']:.1%}")
        print(f"  â€¢ å¹³å‡å“åº”æ—¶é—´: {stats['efficiency_metrics']['mean_response_time']:.3f}s")
        print(f"  â€¢ å¹³å‡é€šä¿¡å¼€é”€: {stats['efficiency_metrics']['mean_communication_overhead']:.3f}s")
        
        comm_analysis = stats['communication_analysis']
        print(f"\né€šä¿¡åˆ†æ:")
        print(f"  â€¢ å¹³å‡ä¼ è¾“æ—¶é—´: {comm_analysis['avg_transmission_time']:.4f}s")
        print(f"  â€¢ å¹³å‡ç½‘ç»œè·³æ•°: {comm_analysis['avg_network_hops']:.1f}")
        print(f"  â€¢ å¹³å‡å¸¦å®½ä½¿ç”¨: {comm_analysis['avg_bandwidth_usage']:.1f} Mbps")
        print(f"  â€¢ å¹³å‡å»¶è¿Ÿ: {comm_analysis['avg_latency']:.1f} ms")
        
        server_analysis = stats['server_usage']
        print(f"\næœåŠ¡å™¨ä½¿ç”¨åˆ†æ:")
        print(f"  â€¢ æ´»è·ƒæœåŠ¡å™¨æ•°: {server_analysis['active_servers']}")
        print(f"  â€¢ æœåŠ¡å™¨å¤šæ ·æ€§: {server_analysis['server_diversity']:.1%}")
        print(f"  â€¢ è´Ÿè½½å‡è¡¡ç³»æ•°: {server_analysis['utilization_balance_coefficient']:.3f}")
        
        model_analysis = stats['model_usage']
        print(f"\næ¨¡å‹ä½¿ç”¨åˆ†æ:")
        print(f"  â€¢ æ¨¡å‹ç±»å‹å¤šæ ·æ€§: {model_analysis['model_diversity']}")
        print(f"  â€¢ æœ€å¸¸ç”¨æ¨¡å‹ç±»å‹: {model_analysis['most_used_model']}")
        
        print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  â€¢ JSONæŠ¥å‘Š: Random_inference.json")
        print(f"  â€¢ CSVæ–‡ä»¶: Random_*.csv (7ä¸ªæ–‡ä»¶)")
        print(f"    - active_server_usage_distribution.csv")
        print(f"    - communication_efficiency.csv")
        print(f"    - communication_overhead_distribution.csv")
        print(f"    - model_type_usage.csv")
        print(f"    - network_performance_metrics.csv")
        print(f"    - reward_distribution.csv")
        print(f"    - task_success_rate.csv")


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = RandomAlgorithmAnalyzer(server_id="Server4")
    
    # è¿è¡Œåˆ†æ
    analyzer.run_analysis(n_episodes=200)


if __name__ == "__main__":
    main()
