#!/usr/bin/env python3
"""
Enhanced Result Analysis Tool
åˆ†ææ¨ç†ç»“æœå’Œè®­ç»ƒæ•°æ®ï¼Œç»™å‡ºæ¸…æ™°æ˜“æ‡‚çš„è¯„ä»·
"""

import json
import numpy as np
from pathlib import Path
import sys

def load_training_data(filename):
    """Load training data"""
    script_dir = Path(__file__).parent  # vamappo/src
    results_dir = script_dir.parent / "results"  # vamappo/results
    data_path = results_dir / filename
    
    print(f"Looking for training data at: {data_path.resolve()}")
    
    if not data_path.exists():
        print("âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        print(f"Expected path: {data_path}")
        return None
    
    with open(data_path, 'r') as f:
        data = json.load(f)
    
    return data

def analyze_training_data(data):
    """Analyze PPO Value Adaptive training data"""
    print("ğŸ” PPO Value Adaptive è®­ç»ƒæ•°æ®åˆ†æ")
    print("=" * 60)
    
    # è·å–åŸºæœ¬ä¿¡æ¯
    metadata = data.get('metadata', {})
    total_episodes = metadata.get('total_episodes', 0)
    training_duration = metadata.get('training_duration', 0)
    algorithm = metadata.get('algorithm', 'Unknown')
    
    print(f"ğŸ“Š è®­ç»ƒåŸºæœ¬ä¿¡æ¯:")
    print(f"   â€¢ ç®—æ³•: {algorithm}")
    print(f"   â€¢ è®­ç»ƒå›åˆæ•°: {total_episodes}")
    print(f"   â€¢ è®­ç»ƒæ—¶é•¿: {training_duration/3600:.2f} å°æ—¶")
    print(f"   â€¢ å¹³å‡æ¯å›åˆæ—¶é—´: {training_duration/total_episodes:.2f} ç§’")
    print()
    
    # åˆ†æç½®ä¿¡åŒºé—´æ•°æ®
    ci_data = data.get('confidence_intervals', {})
    if ci_data:
        print("ğŸ“ˆ å…³é”®æŒ‡æ ‡ç½®ä¿¡åŒºé—´åˆ†æ (95% CI):")
        print("-" * 50)
        
        # æ€»å¥–åŠ±åˆ†æ
        if 'total_rewards' in ci_data:
            rewards_ci = ci_data['total_rewards']
            final_rewards_ci = ci_data.get('final_performance', {})
            
            print(f"ğŸ¯ å¥–åŠ±æ€§èƒ½:")
            print(f"   â€¢ æ•´ä½“å¹³å‡å¥–åŠ±: {rewards_ci['mean']:.3f} Â± {rewards_ci['ci_width']/2:.3f}")
            print(f"   â€¢ ç½®ä¿¡åŒºé—´: [{rewards_ci['ci_lower']:.3f}, {rewards_ci['ci_upper']:.3f}]")
            print(f"   â€¢ ç›¸å¯¹ç²¾åº¦: Â±{rewards_ci['relative_ci_width_percent']:.2f}%")
            
            if final_rewards_ci:
                print(f"   â€¢ æœ€ç»ˆæ€§èƒ½: {final_rewards_ci['mean']:.3f} Â± {final_rewards_ci['ci_width']/2:.3f}")
                print(f"   â€¢ æœ€ç»ˆç½®ä¿¡åŒºé—´: [{final_rewards_ci['ci_lower']:.3f}, {final_rewards_ci['ci_upper']:.3f}]")
                print(f"   â€¢ æœ€ç»ˆç²¾åº¦: Â±{final_rewards_ci['relative_ci_width_percent']:.2f}%")
                
                # æ€§èƒ½æ”¹è¿›
                improvement = ((final_rewards_ci['mean'] - rewards_ci['mean']) / rewards_ci['mean']) * 100
                print(f"   â€¢ æ€§èƒ½æå‡: {improvement:.1f}%")
        
        print()
        
        # å®Œæˆç‡åˆ†æ
        if 'completion_rates' in ci_data:
            completion_ci = ci_data['completion_rates']
            final_completion_ci = ci_data.get('final_completion_rate', {})
            
            print(f"âœ… ä»»åŠ¡å®Œæˆç‡:")
            print(f"   â€¢ æ•´ä½“å®Œæˆç‡: {completion_ci['mean']:.1%} Â± {completion_ci['ci_width']/2:.1%}")
            print(f"   â€¢ ç½®ä¿¡åŒºé—´: [{completion_ci['ci_lower']:.1%}, {completion_ci['ci_upper']:.1%}]")
            print(f"   â€¢ ç›¸å¯¹ç²¾åº¦: Â±{completion_ci['relative_ci_width_percent']:.2f}%")
            
            if final_completion_ci:
                print(f"   â€¢ æœ€ç»ˆå®Œæˆç‡: {final_completion_ci['mean']:.1%} Â± {final_completion_ci['ci_width']/2:.1%}")
                print(f"   â€¢ æœ€ç»ˆç½®ä¿¡åŒºé—´: [{final_completion_ci['ci_lower']:.1%}, {final_completion_ci['ci_upper']:.1%}]")
                
                # å®Œæˆç‡æ”¹è¿›
                completion_improvement = ((final_completion_ci['mean'] - completion_ci['mean']) / completion_ci['mean']) * 100
                print(f"   â€¢ å®Œæˆç‡æå‡: {completion_improvement:.1f}%")
        
        print()
        
        # è‡ªé€‚åº”å­¦ä¹ ç‡åˆ†æ
        if 'adaptive_lr_factors' in ci_data:
            lr_ci = ci_data['adaptive_lr_factors']
            final_lr_ci = ci_data.get('final_adaptive_lr', {})
            
            print(f"ğŸ”§ è‡ªé€‚åº”å­¦ä¹ ç‡:")
            print(f"   â€¢ æ•´ä½“LRå› å­: {lr_ci['mean']:.3f} Â± {lr_ci['ci_width']/2:.3f}")
            print(f"   â€¢ ç½®ä¿¡åŒºé—´: [{lr_ci['ci_lower']:.3f}, {lr_ci['ci_upper']:.3f}]")
            print(f"   â€¢ ç›¸å¯¹ç²¾åº¦: Â±{lr_ci['relative_ci_width_percent']:.2f}%")
            
            if final_lr_ci:
                print(f"   â€¢ æœ€ç»ˆLRå› å­: {final_lr_ci['mean']:.3f} Â± {final_lr_ci['ci_width']/2:.3f}")
                print(f"   â€¢ æ”¶æ•›ç²¾åº¦: Â±{final_lr_ci['relative_ci_width_percent']:.2f}%")
        
        print()
        
        # ä»·å€¼ä¸ç¡®å®šæ€§åˆ†æ
        if 'value_uncertainties' in ci_data:
            uncertainty_ci = ci_data['value_uncertainties']
            final_uncertainty_ci = ci_data.get('final_uncertainty', {})
            
            print(f"ğŸ² ä»·å€¼ä¸ç¡®å®šæ€§:")
            print(f"   â€¢ æ•´ä½“ä¸ç¡®å®šæ€§: {uncertainty_ci['mean']:.4f} Â± {uncertainty_ci['ci_width']/2:.4f}")
            print(f"   â€¢ ç½®ä¿¡åŒºé—´: [{uncertainty_ci['ci_lower']:.4f}, {uncertainty_ci['ci_upper']:.4f}]")
            
            if final_uncertainty_ci:
                print(f"   â€¢ æœ€ç»ˆä¸ç¡®å®šæ€§: {final_uncertainty_ci['mean']:.4f} Â± {final_uncertainty_ci['ci_width']/2:.4f}")
                
                # ä¸ç¡®å®šæ€§ä¸‹é™
                uncertainty_reduction = ((uncertainty_ci['mean'] - final_uncertainty_ci['mean']) / uncertainty_ci['mean']) * 100
                print(f"   â€¢ ä¸ç¡®å®šæ€§é™ä½: {uncertainty_reduction:.1f}%")
        
        print()
    
    # ç¨³å®šæ€§åˆ†æ
    stability = data.get('stability_metrics', {})
    if stability:
        print("ğŸ“Š è®­ç»ƒç¨³å®šæ€§åˆ†æ:")
        print("-" * 30)
        
        reward_cv = stability.get('reward_coefficient_of_variation_percent', 0)
        trend_corr = stability.get('reward_trend_correlation', 0)
        lr_cv = stability.get('adaptive_lr_coefficient_of_variation_percent', 0)
        
        print(f"   â€¢ å¥–åŠ±å˜å¼‚ç³»æ•°: {reward_cv:.2f}%")
        print(f"   â€¢ è¶‹åŠ¿ç›¸å…³æ€§: {trend_corr:.3f}")
        print(f"   â€¢ LRå› å­å˜å¼‚ç³»æ•°: {lr_cv:.2f}%")
        
        # ç¨³å®šæ€§è¯„ä¼°
        if reward_cv < 10:
            stability_grade = "ä¼˜ç§€ ğŸ¯"
        elif reward_cv < 20:
            stability_grade = "è‰¯å¥½ ğŸ“ˆ"
        elif reward_cv < 30:
            stability_grade = "ä¸€èˆ¬ ğŸ“Š"
        else:
            stability_grade = "è¾ƒå·® ğŸ“‰"
        
        print(f"   â€¢ å¥–åŠ±ç¨³å®šæ€§: {stability_grade}")
        
        if trend_corr > 0.8:
            trend_grade = "å¼ºçƒˆä¸Šå‡ ğŸš€"
        elif trend_corr > 0.5:
            trend_grade = "æ˜æ˜¾ä¸Šå‡ ğŸ“ˆ"
        elif trend_corr > 0.2:
            trend_grade = "è½»å¾®ä¸Šå‡ ğŸ“Š"
        else:
            trend_grade = "æ— æ˜æ˜¾è¶‹åŠ¿ ğŸ“‰"
        
        print(f"   â€¢ å­¦ä¹ è¶‹åŠ¿: {trend_grade}")
        print()
    
    # ç»¼åˆè¯„ä»·
    print("ğŸ† ç»¼åˆè®­ç»ƒè¯„ä»·:")
    print("-" * 30)
    
    # è®¡ç®—ç»¼åˆå¾—åˆ†
    scores = {}
    
    if ci_data.get('final_performance'):
        final_reward = ci_data['final_performance']['mean']
        scores['performance'] = min(100, (final_reward / 10) * 100)  # å‡è®¾æ»¡åˆ†æ˜¯10
    
    if ci_data.get('final_completion_rate'):
        final_completion = ci_data['final_completion_rate']['mean']
        scores['completion'] = final_completion * 100
    
    if ci_data.get('final_adaptive_lr'):
        lr_precision = ci_data['final_adaptive_lr']['relative_ci_width_percent']
        scores['lr_stability'] = max(0, 100 - lr_precision * 10)
    
    if stability.get('reward_coefficient_of_variation_percent'):
        reward_cv = stability['reward_coefficient_of_variation_percent']
        scores['reward_stability'] = max(0, 100 - reward_cv * 3)
    
    if stability.get('reward_trend_correlation'):
        trend_corr = stability['reward_trend_correlation']
        scores['learning_trend'] = trend_corr * 100
    
    # æ‰“å°å„é¡¹å¾—åˆ†
    for metric, score in scores.items():
        print(f"   â€¢ {metric.replace('_', ' ').title()}: {score:.1f}/100")
    
    if scores:
        overall_score = np.mean(list(scores.values()))
        print(f"   â€¢ ç»¼åˆå¾—åˆ†: {overall_score:.1f}/100")
        
        if overall_score >= 85:
            grade = "ä¼˜ç§€ ğŸ†"
            desc = "è®­ç»ƒæ•ˆæœä¼˜ç§€ï¼Œæ¨¡å‹å·²è¾¾åˆ°é«˜æ€§èƒ½æ°´å¹³"
        elif overall_score >= 75:
            grade = "è‰¯å¥½ ğŸ¥ˆ"
            desc = "è®­ç»ƒæ•ˆæœè‰¯å¥½ï¼Œæ¨¡å‹æ€§èƒ½ç¨³å®š"
        elif overall_score >= 65:
            grade = "åŠæ ¼ ğŸ¥‰"
            desc = "è®­ç»ƒåŸºæœ¬è¾¾æ ‡ï¼Œè¿˜æœ‰æ”¹è¿›ç©ºé—´"
        elif overall_score >= 50:
            grade = "éœ€æ”¹è¿› âš ï¸"
            desc = "è®­ç»ƒæ•ˆæœä¸€èˆ¬ï¼Œéœ€è¦ä¼˜åŒ–"
        else:
            grade = "ä¸ç†æƒ³ âŒ"
            desc = "è®­ç»ƒæ•ˆæœä¸ç†æƒ³ï¼Œéœ€è¦é‡æ–°è®¾è®¡"
        
        print(f"   â€¢ æœ€ç»ˆè¯„çº§: {grade}")
        print(f"   â€¢ è¯„ä»·: {desc}")
    
    print()
    
    # è®­ç»ƒå»ºè®®
    print("ğŸ’¡ è®­ç»ƒä¼˜åŒ–å»ºè®®:")
    print("-" * 25)
    
    suggestions = []
    
    if ci_data.get('final_completion_rate', {}).get('mean', 0) < 0.5:
        suggestions.append("ğŸ¯ æé«˜ä»»åŠ¡å®Œæˆç‡:")
        suggestions.append("   - è°ƒæ•´å¥–åŠ±å‡½æ•°æƒé‡")
        suggestions.append("   - å¢åŠ å®Œæˆå¥–åŠ±")
    
    if stability.get('reward_coefficient_of_variation_percent', 0) > 15:
        suggestions.append("ğŸ“Š æ”¹å–„è®­ç»ƒç¨³å®šæ€§:")
        suggestions.append("   - é™ä½å­¦ä¹ ç‡")
        suggestions.append("   - å¢åŠ è®­ç»ƒæ‰¹æ¬¡å¤§å°")
    
    if ci_data.get('final_adaptive_lr', {}).get('relative_ci_width_percent', 0) > 2:
        suggestions.append("ğŸ”§ ä¼˜åŒ–è‡ªé€‚åº”å­¦ä¹ ç‡:")
        suggestions.append("   - å¢åŠ LRå¹³æ»‘æœºåˆ¶")
        suggestions.append("   - è°ƒæ•´é€‚åº”é€Ÿåº¦")
    
    if stability.get('reward_trend_correlation', 0) < 0.5:
        suggestions.append("ğŸ“ˆ åŠ å¼ºå­¦ä¹ è¶‹åŠ¿:")
        suggestions.append("   - æ£€æŸ¥æ¢¯åº¦æµ")
        suggestions.append("   - è°ƒæ•´ç½‘ç»œç»“æ„")
    
    if not suggestions:
        suggestions = ["ğŸ‰ è®­ç»ƒè¡¨ç°ä¼˜ç§€ï¼Œç»§ç»­ä¿æŒå½“å‰ç­–ç•¥"]
    
    for suggestion in suggestions:
        print(f"   {suggestion}")

def load_inference_results():
    """Load inference results (original function)"""
    # ä¿®å¤è·¯å¾„ï¼šç¡®ä¿æŒ‡å‘æ­£ç¡®çš„ vamappo/results ç›®å½•
    script_dir = Path(__file__).parent  # vamappo/src
    results_dir = script_dir.parent / "results"  # vamappo/results
    report_path = results_dir / "inference_report_1000000.json"
    
    print(f"Looking for file at: {report_path.resolve()}")
    
    if not report_path.exists():
        print("âŒ æ¨ç†æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨")
        print(f"Expected path: {report_path}")
        return None
    
    with open(report_path, 'r') as f:
        data = json.load(f)
    
    return data

def analyze_performance(data):
    """Analyze and interpret performance"""
    print("ğŸ” åˆ†å¸ƒå¼PPOæ¨¡å‹æ¨ç†ç»“æœåˆ†æ")
    print("=" * 50)
    
    # å…¼å®¹æ–°æ—§æ ¼å¼çš„æ€§èƒ½æŒ‡æ ‡è·å–
    if 'enhanced_performance_statistics' in data:
        perf_stats = data['enhanced_performance_statistics']
        analysis_type = "å¢å¼ºç‰ˆ"
    elif 'performance_statistics' in data:
        perf_stats = data['performance_statistics']
        analysis_type = "æ ‡å‡†ç‰ˆ"
    else:
        print("âŒ æ— æ³•æ‰¾åˆ°æ€§èƒ½ç»Ÿè®¡æ•°æ®")
        return
    
    # è·å–æ€§èƒ½æŒ‡æ ‡
    reward_stats = perf_stats['reward_metrics']
    completion_stats = perf_stats['completion_metrics']
    efficiency_stats = perf_stats['efficiency_metrics']
    model_usage = perf_stats['model_usage']
    server_usage = perf_stats['server_usage']
    
    print(f"ğŸ“Š æµ‹è¯•è§„æ¨¡: {data['inference_metadata']['total_episodes']} ä¸ªæµ‹è¯•episode ({analysis_type})")
    print()
    
    # 1. å¥–åŠ±åˆ†æ
    print("ğŸ¯ å¥–åŠ±è¡¨ç°åˆ†æ:")
    avg_reward = reward_stats['mean']
    std_reward = reward_stats['std']
    print(f"   â€¢ å¹³å‡å¥–åŠ±: {avg_reward:.2f} Â± {std_reward:.2f}")
    print(f"   â€¢ å¥–åŠ±èŒƒå›´: [{reward_stats['min']:.2f}, {reward_stats['max']:.2f}]")
    
    # è¯„åˆ¤å¥–åŠ±è¡¨ç°
    if avg_reward >= 40:
        reward_grade = "ä¼˜ç§€ â­â­â­â­â­"
        reward_desc = "æ¨¡å‹å†³ç­–è´¨é‡å¾ˆé«˜"
    elif avg_reward >= 30:
        reward_grade = "è‰¯å¥½ â­â­â­â­"
        reward_desc = "æ¨¡å‹å†³ç­–è´¨é‡è¾ƒå¥½"
    elif avg_reward >= 20:
        reward_grade = "ä¸€èˆ¬ â­â­â­"
        reward_desc = "æ¨¡å‹å†³ç­–è´¨é‡ä¸­ç­‰"
    elif avg_reward >= 10:
        reward_grade = "è¾ƒå·® â­â­"
        reward_desc = "æ¨¡å‹å†³ç­–éœ€è¦æ”¹è¿›"
    else:
        reward_grade = "å¾ˆå·® â­"
        reward_desc = "æ¨¡å‹å†³ç­–æœ‰ä¸¥é‡é—®é¢˜"
    
    print(f"   â€¢ è¯„çº§: {reward_grade}")
    print(f"   â€¢ è¯„ä»·: {reward_desc}")
    print()
    
    # 2. å¢å¼ºçš„ä»»åŠ¡å®Œæˆåˆ†æ
    print("âœ… ä»»åŠ¡å®Œæˆåˆ†æ:")
    completion_rate = completion_stats['mean_completion_rate']
    success_rate = completion_stats['success_rate']
    print(f"   â€¢ å¹³å‡å®Œæˆç‡: {completion_rate:.1%}")
    print(f"   â€¢ ä»»åŠ¡æˆåŠŸç‡: {success_rate:.1%}")
    
    # å¦‚æœæœ‰å¢å¼ºæŒ‡æ ‡ï¼Œæ˜¾ç¤ºé¢å¤–ä¿¡æ¯
    if 'total_successful_episodes' in completion_stats:
        successful_episodes = completion_stats['total_successful_episodes']
        print(f"   â€¢ æˆåŠŸå®Œæˆçš„ä»»åŠ¡æ•°: {successful_episodes}")
        
    if 'completion_consistency' in completion_stats:
        consistency = completion_stats['completion_consistency']
        print(f"   â€¢ å®Œæˆç‡ä¸€è‡´æ€§: {consistency:.3f}")
    
    # ä»»åŠ¡å®Œæˆè´¨é‡è¯„ä¼°
    if success_rate >= 0.8:
        task_grade = "ä¼˜ç§€ ğŸ¯"
        task_desc = "ä»»åŠ¡å®Œæˆè´¨é‡å¾ˆé«˜"
    elif success_rate >= 0.6:
        task_grade = "è‰¯å¥½ âœ…"
        task_desc = "ä»»åŠ¡å®Œæˆè¡¨ç°è‰¯å¥½"
    elif success_rate >= 0.4:
        task_grade = "ä¸€èˆ¬ ğŸ“‹"
        task_desc = "ä»»åŠ¡å®Œæˆè¡¨ç°ä¸­ç­‰"
    elif success_rate >= 0.2:
        task_grade = "è¾ƒå·® âš ï¸"
        task_desc = "ä»»åŠ¡å®Œæˆéœ€è¦æ”¹è¿›"
    else:
        task_grade = "å¾ˆå·® âŒ"
        task_desc = "ä»»åŠ¡å®Œæˆæœ‰ä¸¥é‡é—®é¢˜"
    
    print(f"   â€¢ ä»»åŠ¡å®Œæˆè¯„çº§: {task_grade}")
    print(f"   â€¢ è¯„ä»·: {task_desc}")
    print()
    
    # 3. å¢å¼ºçš„æ•ˆç‡åˆ†æ
    print("âš¡ ç³»ç»Ÿæ•ˆç‡åˆ†æ:")
    avg_response_time = efficiency_stats['mean_response_time']
    load_balance = efficiency_stats['mean_load_balance']
    print(f"   â€¢ å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}ç§’")
    print(f"   â€¢ è´Ÿè½½å‡è¡¡å¾—åˆ†: {load_balance:.3f}")
    
    # å¦‚æœæœ‰å¢å¼ºæŒ‡æ ‡ï¼Œæ˜¾ç¤ºé¢å¤–ä¿¡æ¯
    if 'mean_action_efficiency' in efficiency_stats:
        action_efficiency = efficiency_stats['mean_action_efficiency']
        print(f"   â€¢ åŠ¨ä½œæ‰§è¡Œæ•ˆç‡: {action_efficiency:.3f}")
        
    if 'mean_resource_utilization' in efficiency_stats:
        resource_util = efficiency_stats['mean_resource_utilization']
        print(f"   â€¢ èµ„æºåˆ©ç”¨ç‡: {resource_util:.3f}")
    
    if avg_response_time < 0.05:
        time_grade = "éå¸¸å¿« ğŸš€"
    elif avg_response_time < 0.1:
        time_grade = "è¾ƒå¿« âš¡"
    elif avg_response_time < 0.5:
        time_grade = "æ­£å¸¸ â±ï¸"
    else:
        time_grade = "è¾ƒæ…¢ ğŸŒ"
    
    print(f"   â€¢ å“åº”é€Ÿåº¦: {time_grade}")
    print()
    
    # 4. å¢å¼ºçš„èµ„æºä½¿ç”¨åˆ†æ
    print("ğŸ–¥ï¸ èµ„æºä½¿ç”¨åˆ†æ:")
    most_used_model = model_usage.get('most_used_model', 'N/A')
    model_percentages = model_usage.get('usage_percentages', {})
    most_used_server = server_usage['most_used_server']
    balance_coeff = server_usage['utilization_balance_coefficient']
    
    print(f"   â€¢ æœ€å¸¸ç”¨æ¨¡å‹ç±»å‹: {most_used_model}")
    print("   â€¢ æ¨¡å‹ç±»å‹ä½¿ç”¨åˆ†å¸ƒ:")
    for model_type, percentage in model_percentages.items():
        print(f"      - ç±»å‹{model_type}: {percentage:.1f}%")
    
    print(f"   â€¢ æœ€å¸¸ç”¨æœåŠ¡å™¨: #{most_used_server}")
    print(f"   â€¢ æœåŠ¡å™¨è´Ÿè½½å‡è¡¡ç³»æ•°: {balance_coeff:.3f}")
    
    # å¢å¼ºæŒ‡æ ‡
    if 'active_servers' in server_usage:
        active_servers = server_usage['active_servers']
        server_diversity = server_usage.get('server_diversity', 0)
        print(f"   â€¢ æ´»è·ƒæœåŠ¡å™¨æ•°é‡: {active_servers}/25")
        print(f"   â€¢ æœåŠ¡å™¨å¤šæ ·æ€§: {server_diversity:.1%}")
    
    if 'model_diversity' in model_usage:
        model_diversity = model_usage['model_diversity']
        print(f"   â€¢ æ¨¡å‹ç±»å‹å¤šæ ·æ€§: {model_diversity} ç§")
    
    if balance_coeff < 0.5:
        balance_grade = "ä¼˜ç§€ âš–ï¸"
    elif balance_coeff < 1.0:
        balance_grade = "è‰¯å¥½ ğŸ“Š"
    elif balance_coeff < 2.0:
        balance_grade = "ä¸€èˆ¬ ğŸ“ˆ"
    else:
        balance_grade = "ä¸å‡è¡¡ âš ï¸"
    
    print(f"   â€¢ è´Ÿè½½å‡è¡¡è¯„ä»·: {balance_grade}")
    print()
    
    # 5. æœåŠ¡å™¨ä½¿ç”¨è¯¦æƒ…
    total_usage = server_usage['total_usage_per_server']
    active_servers = sum(1 for usage in total_usage if usage > 0)
    total_servers = len(total_usage)
    
    print("ğŸŒ æœåŠ¡å™¨ä½¿ç”¨è¯¦æƒ…:")
    print(f"   â€¢ æ´»è·ƒæœåŠ¡å™¨: {active_servers}/{total_servers}")
    print(f"   â€¢ æœåŠ¡å™¨åˆ©ç”¨ç‡: {active_servers/total_servers:.1%}")
    
    # æ˜¾ç¤ºæœ€æ´»è·ƒçš„å‡ ä¸ªæœåŠ¡å™¨
    server_usage_pairs = [(i, usage) for i, usage in enumerate(total_usage) if usage > 0]
    server_usage_pairs.sort(key=lambda x: x[1], reverse=True)
    
    print("   â€¢ ä½¿ç”¨æœ€å¤šçš„5ä¸ªæœåŠ¡å™¨:")
    for i, (server_id, usage) in enumerate(server_usage_pairs[:5]):
        print(f"      {i+1}. æœåŠ¡å™¨#{server_id}: {usage}æ¬¡")
    print()
    
    # 6. å¢å¼ºçš„ç»¼åˆè¯„ä»·
    print("ğŸ–ï¸ ç»¼åˆæ€§èƒ½è¯„ä»·:")
    print("-" * 30)
    
    # è®¡ç®—å¢å¼ºçš„ç»¼åˆå¾—åˆ†
    reward_score = min(100, max(0, avg_reward * 2))  # å¥–åŠ±è½¬æ¢ä¸º0-100åˆ†
    efficiency_score = 100 if avg_response_time < 0.02 else max(0, 100 - avg_response_time * 1000)
    balance_score = max(0, 100 - balance_coeff * 30)
    utilization_score = (active_servers / total_servers) * 100
    success_score = success_rate * 100  # æˆåŠŸç‡å¾—åˆ†
    
    # å¦‚æœæœ‰åŠ¨ä½œæ•ˆç‡æŒ‡æ ‡ï¼ŒåŠ å…¥è®¡ç®—
    if 'mean_action_efficiency' in efficiency_stats:
        action_efficiency = efficiency_stats['mean_action_efficiency']
        action_score = action_efficiency * 100
        overall_score = (reward_score * 0.3 + efficiency_score * 0.2 + 
                        balance_score * 0.15 + utilization_score * 0.1 +
                        success_score * 0.2 + action_score * 0.05)
        print(f"   â€¢ åŠ¨ä½œæ•ˆç‡å¾—åˆ†: {action_score:.1f}/100")
    else:
        overall_score = (reward_score * 0.4 + efficiency_score * 0.3 + 
                        balance_score * 0.2 + utilization_score * 0.1)
    
    print(f"   â€¢ å†³ç­–è´¨é‡å¾—åˆ†: {reward_score:.1f}/100")
    print(f"   â€¢ å“åº”æ•ˆç‡å¾—åˆ†: {efficiency_score:.1f}/100")
    print(f"   â€¢ è´Ÿè½½å‡è¡¡å¾—åˆ†: {balance_score:.1f}/100")
    print(f"   â€¢ èµ„æºåˆ©ç”¨å¾—åˆ†: {utilization_score:.1f}/100")
    print(f"   â€¢ ä»»åŠ¡æˆåŠŸå¾—åˆ†: {success_score:.1f}/100")
    print(f"   â€¢ ç»¼åˆå¾—åˆ†: {overall_score:.1f}/100")
    
    if overall_score >= 85:
        final_grade = "ä¼˜ç§€ ğŸ†"
        recommendation = "æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼Œå·²è¾¾åˆ°ç”Ÿäº§çº§åˆ«æ ‡å‡†"
    elif overall_score >= 75:
        final_grade = "è‰¯å¥½ ğŸ¥ˆ"
        recommendation = "æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œå¯è€ƒè™‘æŠ•å…¥ä½¿ç”¨"
    elif overall_score >= 65:
        final_grade = "åŠæ ¼ ğŸ¥‰"
        recommendation = "æ¨¡å‹åŸºæœ¬è¾¾æ ‡ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–"
    elif overall_score >= 50:
        final_grade = "éœ€æ”¹è¿› âš ï¸"
        recommendation = "æ¨¡å‹éœ€è¦é‡è¦æ”¹è¿›æ‰èƒ½æŠ•å…¥ä½¿ç”¨"
    else:
        final_grade = "ä¸åˆæ ¼ âŒ"
        recommendation = "æ¨¡å‹éœ€è¦é‡æ–°è®¾è®¡æˆ–é‡æ–°è®­ç»ƒ"
    
    print(f"   â€¢ æœ€ç»ˆè¯„çº§: {final_grade}")
    print(f"   â€¢ å»ºè®®: {recommendation}")
    print()
    
    # 7. æ™ºèƒ½æ”¹è¿›å»ºè®®
    print("ğŸ’¡ æ™ºèƒ½æ”¹è¿›å»ºè®®:")
    print("-" * 20)
    
    suggestions = []
    
    if success_rate < 0.5:
        suggestions.append("ğŸ¯ ä»»åŠ¡å®Œæˆç‡æ”¹è¿›:")
        suggestions.append("      - ä¼˜åŒ–åŠ¨ä½œé€‰æ‹©ç­–ç•¥")
        suggestions.append("      - æ£€æŸ¥å¥–åŠ±å‡½æ•°è®¾è®¡")
        suggestions.append("      - å¢åŠ ä»»åŠ¡å®Œæˆå¥–åŠ±")
    
    if balance_coeff > 1.5:
        suggestions.append("âš–ï¸ è´Ÿè½½å‡è¡¡æ”¹è¿›:")
        suggestions.append("      - è°ƒæ•´è´Ÿè½½å‡è¡¡æƒé‡")
        suggestions.append("      - å¢åŠ æœåŠ¡å™¨å¤šæ ·æ€§å¥–åŠ±")
        suggestions.append("      - ä¼˜åŒ–åœ°ç†ä½ç½®å› å­")
    
    if avg_reward < 25:
        suggestions.append("ğŸ¯ å†³ç­–è´¨é‡æå‡:")
        suggestions.append("      - ç»§ç»­è®­ç»ƒæ›´å¤šæ­¥æ•°")
        suggestions.append("      - è°ƒæ•´å­¦ä¹ ç‡å‚æ•°")
        suggestions.append("      - ä¼˜åŒ–ç¥ç»ç½‘ç»œç»“æ„")
    
    if active_servers < total_servers * 0.6:
        suggestions.append("ğŸŒ æœåŠ¡å™¨åˆ©ç”¨ç‡æ”¹è¿›:")
        suggestions.append("      - æ£€æŸ¥æœåŠ¡å™¨æ¨¡å‹é…ç½®")
        suggestions.append("      - è°ƒæ•´åœ°ç†ä½ç½®æƒé‡")
        suggestions.append("      - å¢åŠ æ¢ç´¢ç­–ç•¥")
    
    if 'mean_action_efficiency' in efficiency_stats and efficiency_stats['mean_action_efficiency'] < 0.6:
        suggestions.append("âš¡ åŠ¨ä½œæ•ˆç‡æå‡:")
        suggestions.append("      - ä¼˜åŒ–åŠ¨ä½œé€‰æ‹©ç®—æ³•")
        suggestions.append("      - å‡å°‘æ— æ•ˆåŠ¨ä½œ")
        suggestions.append("      - æ”¹è¿›çŠ¶æ€è¡¨ç¤º")
    
    if not suggestions:
        suggestions = ["ğŸ‰ æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰è®­ç»ƒç­–ç•¥"]
    
    for suggestion in suggestions:
        print(f"   {suggestion}")
    
    # 8. æ€§èƒ½è¶‹åŠ¿åˆ†æï¼ˆå¦‚æœæ˜¯å¢å¼ºç‰ˆï¼‰
    if analysis_type == "å¢å¼ºç‰ˆ":
        print()
        print("ğŸ“ˆ æ€§èƒ½è¶‹åŠ¿åˆ†æ:")
        print("-" * 20)
        if success_rate > 0.6:
            print("   âœ… ä»»åŠ¡æˆåŠŸç‡è¡¨ç°è‰¯å¥½ï¼Œæ¨¡å‹å­¦ä¹ æ•ˆæœæ˜¾è‘—")
        if avg_response_time < 0.05:
            print("   ğŸš€ å“åº”é€Ÿåº¦ä¼˜ç§€ï¼Œæ»¡è¶³å®æ—¶æ€§è¦æ±‚")
        if 'mean_action_efficiency' in efficiency_stats and efficiency_stats['mean_action_efficiency'] > 0.7:
            print("   âš¡ åŠ¨ä½œæ‰§è¡Œæ•ˆç‡é«˜ï¼Œèµ„æºä½¿ç”¨åˆç†")
        if balance_coeff < 1.0:
            print("   âš–ï¸ è´Ÿè½½å‡è¡¡è‰¯å¥½ï¼Œç³»ç»Ÿç¨³å®šæ€§å¼º")

def main():
    """Main function with command line argument support"""
    if len(sys.argv) > 1:
        # åˆ†æè®­ç»ƒæ•°æ®
        filename = sys.argv[1]
        print(f"ğŸ” åˆ†æè®­ç»ƒæ•°æ®æ–‡ä»¶: {filename}")
        data = load_training_data(filename)
        if data:
            analyze_training_data(data)
        else:
            print("âŒ æ— æ³•åŠ è½½è®­ç»ƒæ•°æ®æ–‡ä»¶")
    else:
        # é»˜è®¤åˆ†ææ¨ç†ç»“æœ
        print("ğŸ” åˆ†ææ¨ç†ç»“æœ...")
        data = load_inference_results()
        if data:
            analyze_performance(data)
        else:
            print("âŒ æ— æ³•åŠ è½½æ¨ç†ç»“æœæ–‡ä»¶")
            print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
            print("   python inference_analysis.py                    # åˆ†ææ¨ç†ç»“æœ")
            print("   python inference_analysis.py <training_file>    # åˆ†æè®­ç»ƒæ•°æ®")

if __name__ == "__main__":
    main() 